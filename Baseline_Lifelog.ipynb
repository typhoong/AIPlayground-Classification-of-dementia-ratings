{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc16f359-ddb5-4741-92c7-0d74b5328dae",
   "metadata": {},
   "source": [
    "# 수치/놀이터/치매 및 인지능력 판별\n",
    "\n",
    "- original code written by: Kidon Park\n",
    "- modification & explanation by: Taehoon Kim\n",
    "\n",
    "- 이 노트북을 차례로 살펴보며 코드의 빈 곳을 채우며 실행하면 수치 과제의 전반적인 과정을 수행해볼 수 있게 제작되었습니다.\n",
    "\n",
    "## 과제 설명\n",
    "- 실시간 수면/활동 라이프 로그 데이터 수집을 통한 인지능력 모니터링 과제 \n",
    "\n",
    "\n",
    "## 데이터 설명\n",
    "- 입력 데이터 feature\n",
    "  - 반지 형태의 데일리 수면/활동 데이터 수집기를 통해 착용자의 수면 데이터(수면 시작/종료 시간, 수면 점수, 수면방해, 수면 효율, 램수면 시간, 수면의 깊이 등)와 활동 데이터(활동 시작/종료 시간, 운동 시간, 활동 점수, 신진대사량, 회복 시간, 움직인 거리, 칼로리 소모량 등)을 5분 단위로 수집하여 활동->수면->활동 과 같이 사람의 기본적인 삶의 패턴을 24시간 동안 라이프 로그 모니터링한 데이터.\n",
    "\n",
    "\n",
    "- 출력 데이터 label\n",
    "  - CN : Cognitive Normal(인지기능 정상)\n",
    "  - MCI : Mild Cognitive Impairment(경도 인지기능 장애)\n",
    "  - Dem : Dementia(치매)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3d3f1-8f13-44cb-9fe5-58b6a5013468",
   "metadata": {},
   "source": [
    "## 세팅\n",
    "### 라이브러리\n",
    "코드 전반에 사용되는 라이브러리를 설치 및 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af239b2c-b288-476c-bd02-945c2f200b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치되지 않은 라이브러리의 경우, 주석 해제 후 코드를 실행하여 설치\n",
    "# !pip install torch\n",
    "#!pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e3e89e-4d1c-4401-8834-12d07f35fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dee395-bc31-4acb-834c-197f48e9401e",
   "metadata": {},
   "source": [
    "### 기타\n",
    "- SEED 고정 : 시드를 고정하여 실행하면, 같은 코드를 여러 번 실행한 결과에 일관성을 부여합니다.\n",
    "- device 설정 : GPU를 사용하기 위해서 지정합니다.\n",
    "- 디렉토리 설정 : 추후 반복적으로 사용하게 될 현재 디렉토리 경로를 저장합니다.\n",
    "  데이터는 현재 디렉토리의 `data/`폴더 안에 저장합니다.  \n",
    "- working directory 구조  \n",
    "  |--code.ipynb  \n",
    "  |--data/  \n",
    "  |--|--train/  \n",
    "  |--|--|--train.csv  \n",
    "  |--|--test/  \n",
    "  |--|--|--test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b95e338-a4dc-40b7-a5b6-2186b7d37003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED 고정\n",
    "RANDOM_SEED = 10\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# 경로 설정\n",
    "ROOT_PATH = '/workspace/NIPA_playground/03_final/08_lifelog/'\n",
    "DATA_DIR = '/workspace/NIPA_playground/03_final/08_lifelog/'\n",
    "\n",
    "# train / val set 분할 비율 설정\n",
    "TRAIN_RATIO = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e85371-f306-43ec-b617-a655fb4c5d27",
   "metadata": {},
   "source": [
    "### EDA (Explaratory Data Analylsis)\n",
    "데이터를 간단하게 살펴보겠습니다.  \n",
    "데이터를 이해하기 위해 더 필요하다고 생각되는 부분을 각자 추가해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80045ab-2c04-41dd-85c1-0b042c2e4014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>summary_date</th>\n",
       "      <th>activity_average_met</th>\n",
       "      <th>activity_cal_active</th>\n",
       "      <th>activity_cal_total</th>\n",
       "      <th>activity_class_5min</th>\n",
       "      <th>activity_daily_movement</th>\n",
       "      <th>activity_high</th>\n",
       "      <th>activity_inactive</th>\n",
       "      <th>activity_inactivity_alerts</th>\n",
       "      <th>...</th>\n",
       "      <th>sleep_temperature_delta</th>\n",
       "      <th>sleep_temperature_deviation</th>\n",
       "      <th>sleep_temperature_trend_deviation</th>\n",
       "      <th>timezone</th>\n",
       "      <th>sleep_total</th>\n",
       "      <th>CONVERT(activity_class_5min USING utf8)</th>\n",
       "      <th>CONVERT(activity_met_1min USING utf8)</th>\n",
       "      <th>CONVERT(sleep_hr_5min USING utf8)</th>\n",
       "      <th>CONVERT(sleep_hypnogram_5min USING utf8)</th>\n",
       "      <th>CONVERT(sleep_rmssd_5min USING utf8)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nia+404@rowan.kr</td>\n",
       "      <td>2020-11-27</td>\n",
       "      <td>1.71875</td>\n",
       "      <td>730</td>\n",
       "      <td>2944</td>\n",
       "      <td>...</td>\n",
       "      <td>14346</td>\n",
       "      <td>0</td>\n",
       "      <td>417</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>99.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r</td>\n",
       "      <td>2/1/1/1/1/1/2/2/1/1/1/1/1/1/2/2/2/3/2/2/2/2/2/...</td>\n",
       "      <td>0.9/0.9/1.4/1.9/1.1/0.9/0.9/1.1/1.3/1/0.9/1.1/...</td>\n",
       "      <td>0/73/73/73/72/71/70/71/71/71/70/70/73/72/74/74...</td>\n",
       "      <td>4/2/4/3/3/1/2/2/2/2/2/2/3/3/3/4/4/3/2/2/2/2/2/...</td>\n",
       "      <td>0/10/10/10/11/11/10/12/18/13/14/12/10/10/18/17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nia+404@rowan.kr</td>\n",
       "      <td>2020-11-28</td>\n",
       "      <td>1.40625</td>\n",
       "      <td>342</td>\n",
       "      <td>2449</td>\n",
       "      <td>...</td>\n",
       "      <td>6352</td>\n",
       "      <td>0</td>\n",
       "      <td>473</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>99.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r</td>\n",
       "      <td>1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/2/2/2/2/2/2/...</td>\n",
       "      <td>1.2/1.1/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0....</td>\n",
       "      <td>69/70/69/69/70/72/71/72/70/69/69/69/68/68/63/6...</td>\n",
       "      <td>2/4/2/2/2/2/3/1/2/2/4/4/2/2/2/2/2/2/2/2/2/2/4/...</td>\n",
       "      <td>23/23/26/24/18/13/15/14/17/20/24/30/23/25/22/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nia+404@rowan.kr</td>\n",
       "      <td>2020-11-29</td>\n",
       "      <td>1.46875</td>\n",
       "      <td>401</td>\n",
       "      <td>2544</td>\n",
       "      <td>...</td>\n",
       "      <td>7297</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>99.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r</td>\n",
       "      <td>1/1/1/1/1/1/1/2/1/1/1/1/2/2/2/2/2/1/1/1/1/1/2/...</td>\n",
       "      <td>1.1/1.1/1.2/1.1/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0....</td>\n",
       "      <td>0/74/73/73/74/74/74/71/71/70/70/69/70/68/66/69...</td>\n",
       "      <td>4/2/4/4/1/1/1/4/4/4/4/4/4/4/2/3/4/2/2/4/2/2/2/...</td>\n",
       "      <td>0/11/14/20/13/14/14/16/27/29/27/20/19/19/14/12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nia+404@rowan.kr</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>27</td>\n",
       "      <td>1850</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>99.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r</td>\n",
       "      <td>2/1/2/2/1/2/1/1/2/1/1/1/1/1/2/1/1/1/1/1/2/2/2/...</td>\n",
       "      <td>0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/...</td>\n",
       "      <td>73/70/71/72/75/75/73/70/70/70/67/63/63/63/63/6...</td>\n",
       "      <td>4/4/4/4/3/3/3/2/4/4/4/2/2/2/2/2/2/2/2/4/2/2/2/...</td>\n",
       "      <td>24/28/19/17/12/10/17/20/23/23/25/31/26/25/34/3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nia+404@rowan.kr</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>1.46875</td>\n",
       "      <td>333</td>\n",
       "      <td>2518</td>\n",
       "      <td>...</td>\n",
       "      <td>5861</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>99.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r</td>\n",
       "      <td>1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/2/2/3/3/2/...</td>\n",
       "      <td>0.9/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0....</td>\n",
       "      <td>0/0/0/0/0/0/0/0/69/69/71/69/65/66/64/64/65/66/...</td>\n",
       "      <td>4/4/4/4/4/4/4/4/4/4/4/2/2/2/2/3/3/2/4/4/4/2/2/...</td>\n",
       "      <td>0/0/0/0/0/0/0/0/21/22/26/23/19/29/22/17/14/13/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              EMAIL summary_date  activity_average_met  activity_cal_active  \\\n",
       "0  nia+404@rowan.kr   2020-11-27               1.71875                  730   \n",
       "1  nia+404@rowan.kr   2020-11-28               1.40625                  342   \n",
       "2  nia+404@rowan.kr   2020-11-29               1.46875                  401   \n",
       "3  nia+404@rowan.kr   2020-11-30               0.34375                   27   \n",
       "4  nia+404@rowan.kr   2020-12-01               1.46875                  333   \n",
       "\n",
       "   activity_cal_total activity_class_5min  activity_daily_movement  \\\n",
       "0                2944                 ...                    14346   \n",
       "1                2449                 ...                     6352   \n",
       "2                2544                 ...                     7297   \n",
       "3                1850                 ...                      491   \n",
       "4                2518                 ...                     5861   \n",
       "\n",
       "   activity_high  activity_inactive  activity_inactivity_alerts  ...  \\\n",
       "0              0                417                           0  ...   \n",
       "1              0                473                           0  ...   \n",
       "2              0                586                           0  ...   \n",
       "3              0                176                           0  ...   \n",
       "4              0                646                           0  ...   \n",
       "\n",
       "   sleep_temperature_delta  sleep_temperature_deviation  \\\n",
       "0                    -0.12                        -0.12   \n",
       "1                    -0.32                        -0.32   \n",
       "2                     0.07                         0.07   \n",
       "3                    -0.41                        -0.41   \n",
       "4                    -0.27                        -0.27   \n",
       "\n",
       "  sleep_temperature_trend_deviation  timezone  sleep_total  \\\n",
       "0                             99.99       NaN           \\r   \n",
       "1                             99.99       NaN           \\r   \n",
       "2                             99.99       NaN           \\r   \n",
       "3                             99.99       NaN           \\r   \n",
       "4                             99.99       NaN           \\r   \n",
       "\n",
       "             CONVERT(activity_class_5min USING utf8)  \\\n",
       "0  2/1/1/1/1/1/2/2/1/1/1/1/1/1/2/2/2/3/2/2/2/2/2/...   \n",
       "1  1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/2/2/2/2/2/2/...   \n",
       "2  1/1/1/1/1/1/1/2/1/1/1/1/2/2/2/2/2/1/1/1/1/1/2/...   \n",
       "3  2/1/2/2/1/2/1/1/2/1/1/1/1/1/2/1/1/1/1/1/2/2/2/...   \n",
       "4  1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/2/2/3/3/2/...   \n",
       "\n",
       "               CONVERT(activity_met_1min USING utf8)  \\\n",
       "0  0.9/0.9/1.4/1.9/1.1/0.9/0.9/1.1/1.3/1/0.9/1.1/...   \n",
       "1  1.2/1.1/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0....   \n",
       "2  1.1/1.1/1.2/1.1/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0....   \n",
       "3  0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/...   \n",
       "4  0.9/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0.9/0....   \n",
       "\n",
       "                   CONVERT(sleep_hr_5min USING utf8)  \\\n",
       "0  0/73/73/73/72/71/70/71/71/71/70/70/73/72/74/74...   \n",
       "1  69/70/69/69/70/72/71/72/70/69/69/69/68/68/63/6...   \n",
       "2  0/74/73/73/74/74/74/71/71/70/70/69/70/68/66/69...   \n",
       "3  73/70/71/72/75/75/73/70/70/70/67/63/63/63/63/6...   \n",
       "4  0/0/0/0/0/0/0/0/69/69/71/69/65/66/64/64/65/66/...   \n",
       "\n",
       "            CONVERT(sleep_hypnogram_5min USING utf8)  \\\n",
       "0  4/2/4/3/3/1/2/2/2/2/2/2/3/3/3/4/4/3/2/2/2/2/2/...   \n",
       "1  2/4/2/2/2/2/3/1/2/2/4/4/2/2/2/2/2/2/2/2/2/2/4/...   \n",
       "2  4/2/4/4/1/1/1/4/4/4/4/4/4/4/2/3/4/2/2/4/2/2/2/...   \n",
       "3  4/4/4/4/3/3/3/2/4/4/4/2/2/2/2/2/2/2/2/4/2/2/2/...   \n",
       "4  4/4/4/4/4/4/4/4/4/4/4/2/2/2/2/3/3/2/4/4/4/2/2/...   \n",
       "\n",
       "                CONVERT(sleep_rmssd_5min USING utf8)  \n",
       "0  0/10/10/10/11/11/10/12/18/13/14/12/10/10/18/17...  \n",
       "1  23/23/26/24/18/13/15/14/17/20/24/30/23/25/22/1...  \n",
       "2  0/11/14/20/13/14/14/16/27/29/27/20/19/19/14/12...  \n",
       "3  24/28/19/17/12/10/17/20/23/23/25/31/26/25/34/3...  \n",
       "4  0/0/0/0/0/0/0/0/21/22/26/23/19/29/22/17/14/13/...  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR,'train','train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, 'test','test.csv'))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffbcda2f-47eb-44fc-a2d7-988174df71fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_EMAIL</th>\n",
       "      <th>DIAG_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nia+315@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nia+220@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nia+096@rowan.kr</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nia+163@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nia+396@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SAMPLE_EMAIL DIAG_NM\n",
       "0  nia+315@rowan.kr      CN\n",
       "1  nia+220@rowan.kr      CN\n",
       "2  nia+096@rowan.kr     MCI\n",
       "3  nia+163@rowan.kr      CN\n",
       "4  nia+396@rowan.kr      CN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_df = pd.read_csv(os.path.join(DATA_DIR, 'train','train_label.csv'))\n",
    "train_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62357bf6-81a6-4e35-8e54-9a1dacbcba8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>summary_date</th>\n",
       "      <th>activity_average_met</th>\n",
       "      <th>activity_cal_active</th>\n",
       "      <th>activity_cal_total</th>\n",
       "      <th>activity_class_5min</th>\n",
       "      <th>activity_daily_movement</th>\n",
       "      <th>activity_high</th>\n",
       "      <th>activity_inactive</th>\n",
       "      <th>activity_inactivity_alerts</th>\n",
       "      <th>...</th>\n",
       "      <th>sleep_temperature_delta</th>\n",
       "      <th>sleep_temperature_deviation</th>\n",
       "      <th>sleep_temperature_trend_deviation</th>\n",
       "      <th>timezone</th>\n",
       "      <th>sleep_total</th>\n",
       "      <th>CONVERT(activity_class_5min USING utf8)</th>\n",
       "      <th>CONVERT(activity_met_1min USING utf8)</th>\n",
       "      <th>CONVERT(sleep_hr_5min USING utf8)</th>\n",
       "      <th>CONVERT(sleep_hypnogram_5min USING utf8)</th>\n",
       "      <th>CONVERT(sleep_rmssd_5min USING utf8)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nia+075@rowan.kr</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>1.738393</td>\n",
       "      <td>627.0</td>\n",
       "      <td>2718.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17125.461981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022292</td>\n",
       "      <td>-0.346215</td>\n",
       "      <td>99.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r</td>\n",
       "      <td>1/1/1/1/1/1/1/1/2/1/1/1/1/1/1/1/1/1/1/1/1/1/2/...</td>\n",
       "      <td>1.4/1.8/1.2/3.9/0.9/0.1/0.9/0.9/1.3/1.2/0.9/0....</td>\n",
       "      <td>71/0/65/64/71/64/0/60/66/69/64/66/61/64/62/66/...</td>\n",
       "      <td>2/2/3/2/3/1/3/2/4/4/2/2/4/4/3/2/1/2/4//2/4/2/2...</td>\n",
       "      <td>44/19/19/16/0/20/32/26/13/14/25/17/22/25/17/14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nia+075@rowan.kr</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>1.442223</td>\n",
       "      <td>137.0</td>\n",
       "      <td>2672.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11410.099490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481816</td>\n",
       "      <td>0.019516</td>\n",
       "      <td>99.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r</td>\n",
       "      <td>1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/...</td>\n",
       "      <td>1.6/0.9/0.9/1.3/3.9/2.9/0.9/0.9/0.9/1.1/0.9/1/...</td>\n",
       "      <td>65/56/56/60/59/58/59/58/57/59/62/60/59/56/54/5...</td>\n",
       "      <td>4/3/3/2/1/2/2/1/3/4/2/3/3/1/3/3/1/2/2/2/2/2/3/...</td>\n",
       "      <td>21/17/23//34/19/17/15/19/19/17/30/29/13/19/21/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nia+075@rowan.kr</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>1.479700</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5497.769969</td>\n",
       "      <td>2.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082092</td>\n",
       "      <td>0.022043</td>\n",
       "      <td>99.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r</td>\n",
       "      <td>1/1/1/1/1/2/2/1/1/1/1/1/1/1/1/1/1/1/1/1/1/2/1/...</td>\n",
       "      <td>1.5/0.9/1.4/0.9/0.9/0.9/3.6/1.5/0.9/0.9/0.9/1....</td>\n",
       "      <td>64/0/57/66/52/0/62/0/61/61/0/54/54/52/0/55/64/...</td>\n",
       "      <td>3/1/4/2/2/2/4/4/3/2/2/3/1/2/1/2/3/4/1/2/2/4/2/...</td>\n",
       "      <td>0/21/0/19/53/30/0/27/0/0/70/0/0/44/0/24/31/0/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nia+075@rowan.kr</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>1.069079</td>\n",
       "      <td>217.0</td>\n",
       "      <td>2653.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3852.789155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177269</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>99.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r</td>\n",
       "      <td>1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/...</td>\n",
       "      <td>4.8/1.9/1/1.3/1.4/1.8//2.2/2.1/1.2/1.2/1.2/2.3...</td>\n",
       "      <td>61/61/63/64/59/62/59/60/62/63/58/65/64/61/61/6...</td>\n",
       "      <td>4/1/2/1/4/2/1/2/1/1/2/2/4/4/2/1/2/3/1/3/2/3/4/...</td>\n",
       "      <td>27/20/15/15/16/17/18/22/16/16/16/37/18/18/16/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nia+075@rowan.kr</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>1.645156</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2327.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4483.044208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037126</td>\n",
       "      <td>-0.110565</td>\n",
       "      <td>99.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r</td>\n",
       "      <td>1/1/1/1/1/2/1/1/2/2/1/1/1/1/1/1/1/1/1/1/1/1/1/...</td>\n",
       "      <td>1.9/1.4/1.2/1.3/1.4/1.7/1.2/1/1.8/1.2/0.9/0.9/...</td>\n",
       "      <td>58/0/60/57/60/63/57/55/56/57/57/0//57/58/56/58...</td>\n",
       "      <td>4/4/2/2/4/4/4/4/2/2/2/4/2/1/4/2/4//2/2/4/4/4/4...</td>\n",
       "      <td>25/33/13/19/14/29/25/19/0/22/0/29/0/37/0/27/0/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              EMAIL summary_date  activity_average_met  activity_cal_active  \\\n",
       "0  nia+075@rowan.kr   2020-10-19              1.738393                627.0   \n",
       "1  nia+075@rowan.kr   2020-10-20              1.442223                137.0   \n",
       "2  nia+075@rowan.kr   2020-10-21              1.479700                175.0   \n",
       "3  nia+075@rowan.kr   2020-10-22              1.069079                217.0   \n",
       "4  nia+075@rowan.kr   2020-10-23              1.645156                 16.0   \n",
       "\n",
       "   activity_cal_total activity_class_5min  activity_daily_movement  \\\n",
       "0              2718.0                 ...             17125.461981   \n",
       "1              2672.0                 ...             11410.099490   \n",
       "2              2514.0                 ...              5497.769969   \n",
       "3              2653.0                 ...              3852.789155   \n",
       "4              2327.0                 ...              4483.044208   \n",
       "\n",
       "   activity_high  activity_inactive  activity_inactivity_alerts  ...  \\\n",
       "0            0.0              588.0                           1  ...   \n",
       "1            0.0              544.0                           1  ...   \n",
       "2            2.0              559.0                           2  ...   \n",
       "3            0.0              671.0                           0  ...   \n",
       "4            0.0              767.0                           0  ...   \n",
       "\n",
       "   sleep_temperature_delta  sleep_temperature_deviation  \\\n",
       "0                -0.022292                    -0.346215   \n",
       "1                 0.481816                     0.019516   \n",
       "2                -0.082092                     0.022043   \n",
       "3                 0.177269                     0.013762   \n",
       "4                -0.037126                    -0.110565   \n",
       "\n",
       "  sleep_temperature_trend_deviation  timezone  sleep_total  \\\n",
       "0                             99.99       NaN           \\r   \n",
       "1                             99.99       NaN           \\r   \n",
       "2                             99.99       NaN           \\r   \n",
       "3                             99.99       NaN           \\r   \n",
       "4                             99.99       NaN           \\r   \n",
       "\n",
       "             CONVERT(activity_class_5min USING utf8)  \\\n",
       "0  1/1/1/1/1/1/1/1/2/1/1/1/1/1/1/1/1/1/1/1/1/1/2/...   \n",
       "1  1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/...   \n",
       "2  1/1/1/1/1/2/2/1/1/1/1/1/1/1/1/1/1/1/1/1/1/2/1/...   \n",
       "3  1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/...   \n",
       "4  1/1/1/1/1/2/1/1/2/2/1/1/1/1/1/1/1/1/1/1/1/1/1/...   \n",
       "\n",
       "               CONVERT(activity_met_1min USING utf8)  \\\n",
       "0  1.4/1.8/1.2/3.9/0.9/0.1/0.9/0.9/1.3/1.2/0.9/0....   \n",
       "1  1.6/0.9/0.9/1.3/3.9/2.9/0.9/0.9/0.9/1.1/0.9/1/...   \n",
       "2  1.5/0.9/1.4/0.9/0.9/0.9/3.6/1.5/0.9/0.9/0.9/1....   \n",
       "3  4.8/1.9/1/1.3/1.4/1.8//2.2/2.1/1.2/1.2/1.2/2.3...   \n",
       "4  1.9/1.4/1.2/1.3/1.4/1.7/1.2/1/1.8/1.2/0.9/0.9/...   \n",
       "\n",
       "                   CONVERT(sleep_hr_5min USING utf8)  \\\n",
       "0  71/0/65/64/71/64/0/60/66/69/64/66/61/64/62/66/...   \n",
       "1  65/56/56/60/59/58/59/58/57/59/62/60/59/56/54/5...   \n",
       "2  64/0/57/66/52/0/62/0/61/61/0/54/54/52/0/55/64/...   \n",
       "3  61/61/63/64/59/62/59/60/62/63/58/65/64/61/61/6...   \n",
       "4  58/0/60/57/60/63/57/55/56/57/57/0//57/58/56/58...   \n",
       "\n",
       "            CONVERT(sleep_hypnogram_5min USING utf8)  \\\n",
       "0  2/2/3/2/3/1/3/2/4/4/2/2/4/4/3/2/1/2/4//2/4/2/2...   \n",
       "1  4/3/3/2/1/2/2/1/3/4/2/3/3/1/3/3/1/2/2/2/2/2/3/...   \n",
       "2  3/1/4/2/2/2/4/4/3/2/2/3/1/2/1/2/3/4/1/2/2/4/2/...   \n",
       "3  4/1/2/1/4/2/1/2/1/1/2/2/4/4/2/1/2/3/1/3/2/3/4/...   \n",
       "4  4/4/2/2/4/4/4/4/2/2/2/4/2/1/4/2/4//2/2/4/4/4/4...   \n",
       "\n",
       "                CONVERT(sleep_rmssd_5min USING utf8)  \n",
       "0  44/19/19/16/0/20/32/26/13/14/25/17/22/25/17/14...  \n",
       "1  21/17/23//34/19/17/15/19/19/17/30/29/13/19/21/...  \n",
       "2  0/21/0/19/53/30/0/27/0/0/70/0/0/44/0/24/31/0/1...  \n",
       "3  27/20/15/15/16/17/18/22/16/16/16/37/18/18/16/1...  \n",
       "4  25/33/13/19/14/29/25/19/0/22/0/29/0/37/0/27/0/...  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4292aa-35e7-41b0-bc44-03357f2654af",
   "metadata": {},
   "source": [
    "#### 코드 채워넣기\n",
    "- 인코딩을 위한 레이블 딕셔너리를 만들어 보세요.\n",
    "- CN(Cognitive Normal, 인지기능 정상)을 '0'에, MCI(Mild Cognitive Impairment, 경도 인지기능 장애)을 '1'에, Dem(Dementia, 치매)을 '2'에 대응시키는 딕셔너리를 생성하여\n",
    "  self.states = {} 꼴로 지정해보세요. (def __init__ 안의 `##### 코드 #####` 부분)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f0612ba-d8f5-4dd6-a17e-c96a6c851387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "                \n",
    "        # 인코딩을 위한 레이블 딕셔너리\n",
    "        self.states = {'CN':0, 'MCI':1, 'Dem':2}\n",
    "        self.inputs, self.labels = self.data_loader(data_dir)\n",
    "\n",
    "    def data_loader(self, path):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "            \n",
    "        if self.mode == 'train':\n",
    "            #if os.path.isfile(os.path.join(self.data_dir, self.mode, self.mode + '_X.pt')):\n",
    "#             if False:\n",
    "#                 inputs = torch.load(os.path.join(self.data_dir, self.mode, self.mode + '_X.pt'))\n",
    "#                 labels = torch.load(os.path.join(self.data_dir, self.mode, self.mode + '_Y.pt'))\n",
    "#                 inputs = inputs[:int(len(inputs)*TRAIN_RATIO)]\n",
    "#                 labels = labels[:int(len(labels)*TRAIN_RATIO)]\n",
    "\n",
    "#             else:\n",
    "            inputs, labels = pd.read_csv(os.path.join(self.data_dir, self.mode, self.mode + '.csv')), pd.read_csv(os.path.join(self.data_dir, self.mode, self.mode + '_label.csv'))\n",
    "            inputs, labels = self.preprocessing(inputs, labels)\n",
    "#                 torch.save(inputs, os.path.join(self.data_dir, self.mode, self.mode + '_X.pt'))\n",
    "#                 torch.save(labels, os.path.join(self.data_dir, self.mode, self.mode + '_Y.pt'))\n",
    "            inputs = inputs[:int(len(inputs)*TRAIN_RATIO)]\n",
    "            labels = labels[:int(len(labels)*TRAIN_RATIO)]\n",
    "\n",
    "            return inputs, labels\n",
    "        \n",
    "        elif self.mode == 'val':\n",
    "            #if os.path.isfile(os.path.join(self.data_dir, 'train/train_X.pt')):\n",
    "#             if False:\n",
    "#                 inputs = torch.load(os.path.join(self.data_dir, 'train/train_X.pt'))\n",
    "#                 labels = torch.load(os.path.join(self.data_dir, 'train/train_Y.pt'))\n",
    "#                 inputs = inputs[int(len(inputs)*TRAIN_RATIO):]\n",
    "#                 labels = labels[int(len(labels)*TRAIN_RATIO):]\n",
    "\n",
    "#             else:\n",
    "            inputs, labels = pd.read_csv(os.path.join(self.data_dir, 'train/train.csv')), pd.read_csv(os.path.join(self.data_dir, 'train/train_label.csv'))\n",
    "            inputs, labels = self.preprocessing(inputs, labels)\n",
    "#                 torch.save(inputs, os.path.join(self.data_dir, self.mode, self.mode + '_X.pt'))\n",
    "#                 torch.save(labels, os.path.join(self.data_dir, self.mode, self.mode + '_Y.pt'))\n",
    "            inputs = inputs[int(len(inputs)*TRAIN_RATIO):]\n",
    "            labels = labels[int(len(labels)*TRAIN_RATIO):]\n",
    "\n",
    "            return inputs, labels\n",
    "\n",
    "    \n",
    "    \n",
    "    def preprocessing(self, inputs, labels):\n",
    "        print('Preprocessing ' + self.mode + ' dataset..')\n",
    "        \n",
    "        # Cut time series length based on the shortest length\n",
    "        train_df = pd.read_csv(os.path.join(DATA_DIR,'train','train.csv'))\n",
    "        test_df = pd.read_csv(os.path.join(DATA_DIR, 'test','test.csv'))\n",
    "        time_series_length= pd.concat([train_df['EMAIL'].value_counts(), test_df['EMAIL'].value_counts()])\n",
    "        shortest_length = time_series_length[-1]\n",
    "        arranged_labels = []\n",
    "\n",
    "        for id in inputs['EMAIL'].unique():\n",
    "            idx = inputs['EMAIL'][inputs['EMAIL'] == id].index\n",
    "            start_idx = idx[0]\n",
    "            end_idx = idx[-1]\n",
    "            inputs.drop(list((range(start_idx + shortest_length , end_idx+1))), axis=0, inplace=True)\n",
    "            inputs = inputs.reset_index(drop=True)\n",
    "\n",
    "        # Selecting usage columns\n",
    "        del_col = ['EMAIL', 'summary_date',\n",
    "                   'activity_class_5min', 'activity_met_1min',\n",
    "                   'sleep_hr_5min', 'sleep_hypnogram_5min', 'sleep_rmssd_5min', 'timezone', 'sleep_total',\n",
    "                   'CONVERT(activity_class_5min USING utf8)', 'CONVERT(activity_met_1min USING utf8)',\n",
    "                   'CONVERT(sleep_hr_5min USING utf8)', 'CONVERT(sleep_hypnogram_5min USING utf8)',\n",
    "                   'CONVERT(sleep_rmssd_5min USING utf8)']\n",
    "        inputs.drop(del_col, axis=1, inplace=True)\n",
    "\n",
    "        #Normalization\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        if self.mode == 'test' :\n",
    "            train_df.drop(del_col, axis=1, inplace=True)\n",
    "            scaler.fit_transform(train_df)\n",
    "            inputs = scaler.transform(inputs)\n",
    "        else:\n",
    "            inputs = scaler.fit_transform(inputs)\n",
    "\n",
    "        # Convert dataframe to tensor\n",
    "        inputs = torch.FloatTensor(inputs).reshape(len(labels), -1, inputs.shape[1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        labels = list(map(lambda x: self.states[x], labels['DIAG_NM'].tolist()))\n",
    "        labels = torch.LongTensor(labels)\n",
    "        #labels = self.label_encoder(labels)\n",
    "        #labels = torch.FloatTensor(labels).rehshape(len(labels),-1)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def label_encoder(self, labels):\n",
    "        try:\n",
    "            labels = list(map(lambda x : self.states[x], labels['DIAG_NM'].tolist()))\n",
    "            return labels\n",
    "        except:\n",
    "            assert 'Invalid states'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index, :, :], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e405319-0d88-4313-b6e6-02a424ecc138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n",
      "Preprocessing train dataset..\n",
      "Loading val dataset..\n",
      "Preprocessing val dataset..\n"
     ]
    }
   ],
   "source": [
    "# DATASET 만들기\n",
    "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train')\n",
    "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val')\n",
    "\n",
    "# 데이터로드 파라미터\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# DATASET 로딩하기\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ac5889-6751-4f55-9bed-76ae5d0590b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066f0ee7-0a54-476b-a165-76553d726de0",
   "metadata": {},
   "source": [
    "## 모델 설계\n",
    "### 사용할 파라미터\n",
    "- `LEARNING_RATE` : 경사하강법(Gradient Descent)을 통해 loss function의 minimum값을 찾아다닐 때, 그 탐색 과정에 있어서의 보폭 정도로 직관적으로 이해 할 수 있습니다. 보폭이 너무 크다면 최적값을 쉽게 지나칠 위험이 있고, 보폭이 너무 작다면 탐색에 걸리는 시간이 길어집니다.\n",
    "- `EPOCHS` : \n",
    "  - 한 번의 epoch는 인공 신경망에서 전체 데이터 셋에 대해 forward pass/backward pass 과정을 거친 것입니다.\n",
    "  - 즉, epoch이 1만큼 지나면, 전체 데이터 셋에 대해 한번의 학습이 완료된 상태입니다.\n",
    "  - 모델을 만들 때 적절한 epoch 값을 설정해야만 underfitting과 overfitting을 방지할 수 있습니다.\n",
    "  - 1 epoch = (데이터 갯수 / batch size) interations\n",
    "- `HIDDEN_SIZE` : \n",
    "    - 신경망에서 인풋 레이어와 아웃풋 레이어 사이의 레이어들을 말합니다.\n",
    "    - 기본적으로 1개의 hidden layer가 있어야 하며 hidden layer의 units의 수는 input units의 수에 배수로 지정하는 것이 일반적입니다.\n",
    "    - 모든 hidden layers들은 같은 수의 units들을 가지고 있어야 합니다.\n",
    "- `EARLY_STOPPING_PATIENCE` :\n",
    "  - 너무 많은 epoch은 overfitting을 일으키고, 너무 적은 epoch은 underfitting을 일으킵니다. 이런 딜레마에 빠지지 않기 위도록 특정 시점에 학습을 멈추는 방법이 early stopping입니다.\n",
    "  - 해당 변수는 validation score가 개선되지 않아도 학습을 몇 에폭 더 진행할 지 결정합니다. 예를 들어 EARLY_STOPPING_PATIENCE를 5로 설정하고 validation score가 10에폭에서 가장 높은 후 다음 에폭부터 줄어든다면, 15에폭까지는 학습을 진행하며 validation score가 더 높아지는지 확인하고, 그렇지 않다면 학습을 중단합니다.\n",
    "- `WEIGHT_DECAY` :\n",
    "  - overfitting을 억제하는 학습 기법의 하나로, 학습된 모델의 복잡도를 줄이기 위해서 학습 중 weight가 너무 큰 값을 가지지 않도록 Loss function에 Weight가 커질 경우에 대한 패널티 항목을 넣습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440f096-c14d-4305-b1d2-4abca2c38844",
   "metadata": {},
   "source": [
    "#### 코드 채워넣기\n",
    "- 모델 학습을 위한 하이퍼 파라미터를 값을 지정해 보세요.\n",
    "- 지정하는 파라미터 값에 따라 모델의 학습 속도와 성능이 달라질 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0a2dad4-909a-4515-9bb3-4c4456f7d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "LEARNING_RATE = 0.005\n",
    "EPOCHS = 500\n",
    "HIDDEN_SIZE = 512\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "WEIGHT_DECAY = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "223581dc-4a72-449e-a88c-6b5eca2f761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device, n_layers=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.device = device\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.h_0 = self.init_hidden(BATCH_SIZE)\n",
    "        self.lstm = nn.LSTM(input_size = input_dim, hidden_size = hidden_dim, num_layers = n_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2 * hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        h_0 = Variable(torch.randn(2 * self.n_layers, batch_size, self.hidden_dim)).to(self.device)\n",
    "        c_0 = Variable(torch.randn(2 * self.n_layers, batch_size, self.hidden_dim)).to(self.device)\n",
    "        return (h_0, c_0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #batch_size = x.shape[0]\n",
    "        #self.h_c = self.init_hidden(batch_size)\n",
    "        lstm_out, self.h_c = self.lstm(x)\n",
    "        output = self.fc(lstm_out[:, -1, :])\n",
    "        return F.softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b4c48da-da69-43b7-b8c3-b1df7ec96036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성하기\n",
    "model = LSTM(input_dim=train_dataset.inputs.shape[2], hidden_dim=512, output_dim=3, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33e93a55-1982-4881-9bf3-b1c580e55566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer, scheduler, loss function, metric function\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
    "metric_fn = f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cffcbd-aba0-48ca-91fa-12cc180893a9",
   "metadata": {},
   "source": [
    "#### 코드 채워넣기\n",
    "- `train_epoch`과 `valid_epoch` 함수에서 data와 target을 위에서 정의한 device에 할당해보세요.  \n",
    "- train_epoch 부분과 valid_epoch 부분에 들어갈 코드는 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62fc0175-bd0d-4679-af4a-e71db6fda363",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, device, loss_fn, metric_fn, optimizer=None, scheduler=None):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metric_fn = metric_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "\n",
    "    def train_epoch(self, dataloader, epoch_index=0):\n",
    "        self.model.train()\n",
    "        self.train_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        for batch_idx, (data, target) in enumerate(dataloader):\n",
    "            data = data.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "            output = self.model(data)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.loss_fn(output, target)\n",
    "            self.train_total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            target_lst.extend(target.tolist())\n",
    "            pred_lst.extend(output.argmax(dim=1).tolist())\n",
    "        self.train_mean_loss = self.train_total_loss / len(dataloader)\n",
    "        self.train_score = f1_score(y_true=target_lst, y_pred=pred_lst, average='macro')\n",
    "        msg = f'Epoch {epoch_index}, Train, loss: {self.train_mean_loss}, Score: {self.train_score}'\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "    def validate_epoch(self, dataloader, epoch_index=0):\n",
    "        self.model.eval()\n",
    "        self.val_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        with torch.no_grad():\n",
    "            for batch_index, (data, target) in enumerate(dataloader):\n",
    "                data = data.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                loss = self.loss_fn(output, target)\n",
    "                self.val_total_loss += loss.item()\n",
    "                target_lst.extend(target.tolist())\n",
    "                pred_lst.extend(output.argmax(dim=1).tolist())\n",
    "            self.val_mean_loss = self.val_total_loss / len(dataloader)\n",
    "            self.validation_score = f1_score(y_true=target_lst, y_pred=pred_lst, average='macro')\n",
    "            msg = f'Epoch {epoch_index}, Validation, loss: {self.val_mean_loss}, Score: {self.validation_score}'\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e049edeb-5578-4047-b221-db5ee471d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "    \n",
    "    Attributes:\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int, verbose: bool)-> None: # logger:logging.RootLogger=None\n",
    "        \"\"\" 초기화\n",
    "\n",
    "        Args:\n",
    "            patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "            weight_path (str): weight 저장경로\n",
    "            verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.stop = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "            # self.save_checkpoint(loss=loss, model=model)\n",
    "\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopper, Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "\n",
    "\n",
    "        elif loss <= self.min_loss:\n",
    "            self.patience_counter = 0\n",
    "            self.save_model = True\n",
    "            msg = f\"Early stopper, Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "            # self.save_checkpoint(loss=loss, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4df3253a-5ab7-4a7d-9c70-7e2badd57dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 셋팅하기\n",
    "trainer = Trainer(model, device, loss_fn, metric_fn, optimizer, scheduler)\n",
    "\n",
    "# Earlystopper 셋팅하기\n",
    "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356c310-aaa9-4291-bb34-0207a2b55a9a",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ade989f-8ca1-4ac9-ba2f-e042d5491f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train, loss: 1.0987197160720825, Score: 0.25218961829131326\n",
      "Epoch 0, Validation, loss: 1.0982635021209717, Score: 0.1858974358974359\n",
      "Epoch 1, Train, loss: 1.0987197160720825, Score: 0.25218961829131326\n",
      "Epoch 1, Validation, loss: 1.0982621908187866, Score: 0.1858974358974359\n",
      "Epoch 2, Train, loss: 1.0987175703048706, Score: 0.25218961829131326\n",
      "Epoch 2, Validation, loss: 1.0982571840286255, Score: 0.1858974358974359\n",
      "Epoch 3, Train, loss: 1.098709225654602, Score: 0.25218961829131326\n",
      "Epoch 3, Validation, loss: 1.0982457399368286, Score: 0.1858974358974359\n",
      "Epoch 4, Train, loss: 1.0986907482147217, Score: 0.25218961829131326\n",
      "Epoch 4, Validation, loss: 1.0982259511947632, Score: 0.1858974358974359\n",
      "Epoch 5, Train, loss: 1.098658561706543, Score: 0.25218961829131326\n",
      "Epoch 5, Validation, loss: 1.0981953144073486, Score: 0.1858974358974359\n",
      "Epoch 6, Train, loss: 1.0986087322235107, Score: 0.25218961829131326\n",
      "Epoch 6, Validation, loss: 1.0981519222259521, Score: 0.1858974358974359\n",
      "Epoch 7, Train, loss: 1.098537802696228, Score: 0.25218961829131326\n",
      "Epoch 7, Validation, loss: 1.0980936288833618, Score: 0.1858974358974359\n",
      "Epoch 8, Train, loss: 1.0984426736831665, Score: 0.2611162472179422\n",
      "Epoch 8, Validation, loss: 1.098018765449524, Score: 0.1858974358974359\n",
      "Epoch 9, Train, loss: 1.098320484161377, Score: 0.26550802108340016\n",
      "Epoch 9, Validation, loss: 1.0979256629943848, Score: 0.1858974358974359\n",
      "Epoch 10, Train, loss: 1.098168969154358, Score: 0.26550802108340016\n",
      "Epoch 10, Validation, loss: 1.0978126525878906, Score: 0.1858974358974359\n",
      "Epoch 11, Train, loss: 1.0979845523834229, Score: 0.26550802108340016\n",
      "Epoch 11, Validation, loss: 1.097678542137146, Score: 0.1858974358974359\n",
      "Epoch 12, Train, loss: 1.0977656841278076, Score: 0.27415777359280186\n",
      "Epoch 12, Validation, loss: 1.0975216627120972, Score: 0.2261904761904762\n",
      "Epoch 13, Train, loss: 1.097509503364563, Score: 0.30409746464967036\n",
      "Epoch 13, Validation, loss: 1.09734046459198, Score: 0.21666666666666667\n",
      "Epoch 14, Train, loss: 1.0972141027450562, Score: 0.3076667024589284\n",
      "Epoch 14, Validation, loss: 1.0971338748931885, Score: 0.2619047619047619\n",
      "Epoch 15, Train, loss: 1.0968769788742065, Score: 0.3228233754549544\n",
      "Epoch 15, Validation, loss: 1.096900224685669, Score: 0.2619047619047619\n",
      "Epoch 16, Train, loss: 1.0964956283569336, Score: 0.32684435447593346\n",
      "Epoch 16, Validation, loss: 1.0966382026672363, Score: 0.25\n",
      "Epoch 17, Train, loss: 1.096068024635315, Score: 0.3176131775031618\n",
      "Epoch 17, Validation, loss: 1.0963462591171265, Score: 0.2913165266106443\n",
      "Epoch 18, Train, loss: 1.0955915451049805, Score: 0.3210831521176349\n",
      "Epoch 18, Validation, loss: 1.0960230827331543, Score: 0.27941176470588236\n",
      "Epoch 19, Train, loss: 1.0950634479522705, Score: 0.340536398467433\n",
      "Epoch 19, Validation, loss: 1.095666766166687, Score: 0.27941176470588236\n",
      "Epoch 20, Train, loss: 1.0944814682006836, Score: 0.3310410077582246\n",
      "Epoch 20, Validation, loss: 1.095275640487671, Score: 0.38888888888888884\n",
      "Epoch 21, Train, loss: 1.093842625617981, Score: 0.39685990338164245\n",
      "Epoch 21, Validation, loss: 1.0948479175567627, Score: 0.38888888888888884\n",
      "Epoch 22, Train, loss: 1.0931440591812134, Score: 0.3697930149406407\n",
      "Epoch 22, Validation, loss: 1.09438157081604, Score: 0.38888888888888884\n",
      "Epoch 23, Train, loss: 1.092382788658142, Score: 0.36222134801993183\n",
      "Epoch 23, Validation, loss: 1.0938748121261597, Score: 0.38888888888888884\n",
      "Epoch 24, Train, loss: 1.0915557146072388, Score: 0.36182873341891314\n",
      "Epoch 24, Validation, loss: 1.0933252573013306, Score: 0.3703703703703704\n",
      "Epoch 25, Train, loss: 1.0906596183776855, Score: 0.36180890083329115\n",
      "Epoch 25, Validation, loss: 1.09273099899292, Score: 0.3703703703703704\n",
      "Epoch 26, Train, loss: 1.0896899700164795, Score: 0.3659858722358722\n",
      "Epoch 26, Validation, loss: 1.0920888185501099, Score: 0.5555555555555555\n",
      "Epoch 27, Train, loss: 1.0886437892913818, Score: 0.39198691172375383\n",
      "Epoch 27, Validation, loss: 1.0913960933685303, Score: 0.5555555555555555\n",
      "Epoch 28, Train, loss: 1.0875164270401, Score: 0.4048319543655892\n",
      "Epoch 28, Validation, loss: 1.090649962425232, Score: 0.5555555555555555\n",
      "Epoch 29, Train, loss: 1.0863025188446045, Score: 0.4195487949021019\n",
      "Epoch 29, Validation, loss: 1.089846134185791, Score: 0.5555555555555555\n",
      "Epoch 30, Train, loss: 1.0849969387054443, Score: 0.42439807383627604\n",
      "Epoch 30, Validation, loss: 1.0889811515808105, Score: 0.5555555555555555\n",
      "Epoch 31, Train, loss: 1.0835927724838257, Score: 0.4339887545646613\n",
      "Epoch 31, Validation, loss: 1.0880497694015503, Score: 0.5555555555555555\n",
      "Epoch 32, Train, loss: 1.082082748413086, Score: 0.4336692811269083\n",
      "Epoch 32, Validation, loss: 1.087046504020691, Score: 0.5555555555555555\n",
      "Epoch 33, Train, loss: 1.0804578065872192, Score: 0.44398775894538606\n",
      "Epoch 33, Validation, loss: 1.0859646797180176, Score: 0.5555555555555555\n",
      "Epoch 34, Train, loss: 1.0787063837051392, Score: 0.45900817957486256\n",
      "Epoch 34, Validation, loss: 1.0847960710525513, Score: 0.5555555555555555\n",
      "Epoch 35, Train, loss: 1.076816201210022, Score: 0.4496144036920087\n",
      "Epoch 35, Validation, loss: 1.0835312604904175, Score: 0.5555555555555555\n",
      "Epoch 36, Train, loss: 1.0747711658477783, Score: 0.4399815965033356\n",
      "Epoch 36, Validation, loss: 1.0821589231491089, Score: 0.5555555555555555\n",
      "Epoch 37, Train, loss: 1.0725513696670532, Score: 0.4109630905211015\n",
      "Epoch 37, Validation, loss: 1.0806645154953003, Score: 0.5925925925925926\n",
      "Epoch 38, Train, loss: 1.0701332092285156, Score: 0.4206732877312988\n",
      "Epoch 38, Validation, loss: 1.079031229019165, Score: 0.5925925925925926\n",
      "Epoch 39, Train, loss: 1.067487120628357, Score: 0.42920461445051616\n",
      "Epoch 39, Validation, loss: 1.077237606048584, Score: 0.5925925925925926\n",
      "Epoch 40, Train, loss: 1.064575433731079, Score: 0.42920461445051616\n",
      "Epoch 40, Validation, loss: 1.075257420539856, Score: 0.5925925925925926\n",
      "Epoch 41, Train, loss: 1.0613524913787842, Score: 0.4328703703703704\n",
      "Epoch 41, Validation, loss: 1.0730572938919067, Score: 0.5925925925925926\n",
      "Epoch 42, Train, loss: 1.0577595233917236, Score: 0.42325182325182326\n",
      "Epoch 42, Validation, loss: 1.0705960988998413, Score: 0.5925925925925926\n",
      "Epoch 43, Train, loss: 1.0537220239639282, Score: 0.4277180406212664\n",
      "Epoch 43, Validation, loss: 1.06782066822052, Score: 0.5925925925925926\n",
      "Epoch 44, Train, loss: 1.0491456985473633, Score: 0.4177389452220696\n",
      "Epoch 44, Validation, loss: 1.064663052558899, Score: 0.5925925925925926\n",
      "Epoch 45, Train, loss: 1.0439079999923706, Score: 0.4177389452220696\n",
      "Epoch 45, Validation, loss: 1.0610384941101074, Score: 0.5925925925925926\n",
      "Epoch 46, Train, loss: 1.0378509759902954, Score: 0.41780231154045194\n",
      "Epoch 46, Validation, loss: 1.0568453073501587, Score: 0.5925925925925926\n",
      "Epoch 47, Train, loss: 1.0307669639587402, Score: 0.4221362769035064\n",
      "Epoch 47, Validation, loss: 1.0519815683364868, Score: 0.5925925925925926\n",
      "Epoch 48, Train, loss: 1.02238130569458, Score: 0.43194602267698917\n",
      "Epoch 48, Validation, loss: 1.0463979244232178, Score: 0.5925925925925926\n",
      "Epoch 49, Train, loss: 1.0123404264450073, Score: 0.43654214559386967\n",
      "Epoch 49, Validation, loss: 1.040188193321228, Score: 0.5925925925925926\n",
      "Epoch 50, Train, loss: 1.0002741813659668, Score: 0.4348290598290598\n",
      "Epoch 50, Validation, loss: 1.0334903001785278, Score: 0.5925925925925926\n",
      "Epoch 51, Train, loss: 0.9861405491828918, Score: 0.42702821869488544\n",
      "Epoch 51, Validation, loss: 1.0257223844528198, Score: 0.5925925925925926\n",
      "Epoch 52, Train, loss: 0.9710139036178589, Score: 0.4358650608650609\n",
      "Epoch 52, Validation, loss: 1.0146876573562622, Score: 0.5925925925925926\n",
      "Epoch 53, Train, loss: 0.9567772746086121, Score: 0.4358650608650609\n",
      "Epoch 53, Validation, loss: 0.9988035559654236, Score: 0.6345029239766081\n",
      "Epoch 54, Train, loss: 0.9434811472892761, Score: 0.4358650608650609\n",
      "Epoch 54, Validation, loss: 0.9845039248466492, Score: 0.6345029239766081\n",
      "Epoch 55, Train, loss: 0.9305640459060669, Score: 0.42397034190560645\n",
      "Epoch 55, Validation, loss: 0.9727879762649536, Score: 0.6345029239766081\n",
      "Epoch 56, Train, loss: 0.9196049571037292, Score: 0.42061471453267774\n",
      "Epoch 56, Validation, loss: 0.9623357057571411, Score: 0.4000000000000001\n",
      "Epoch 57, Train, loss: 0.9099069833755493, Score: 0.398030018761726\n",
      "Epoch 57, Validation, loss: 0.9630197882652283, Score: 0.31746031746031744\n",
      "Epoch 58, Train, loss: 0.8978554010391235, Score: 0.4042610571736786\n",
      "Epoch 58, Validation, loss: 0.9868119955062866, Score: 0.21212121212121213\n",
      "Epoch 59, Train, loss: 0.8885459303855896, Score: 0.3359558316080055\n",
      "Epoch 59, Validation, loss: 1.0068509578704834, Score: 0.2318840579710145\n",
      "Epoch 60, Train, loss: 0.8899165987968445, Score: 0.3234102026554857\n",
      "Epoch 60, Validation, loss: 1.0190047025680542, Score: 0.2318840579710145\n",
      "Epoch 61, Train, loss: 0.8904737234115601, Score: 0.3252999478351591\n",
      "Epoch 61, Validation, loss: 1.0157835483551025, Score: 0.2318840579710145\n",
      "Epoch 62, Train, loss: 0.8889304995536804, Score: 0.3285188331917304\n",
      "Epoch 62, Validation, loss: 1.005469799041748, Score: 0.2318840579710145\n",
      "Epoch 63, Train, loss: 0.8859885931015015, Score: 0.31613756613756616\n",
      "Epoch 63, Validation, loss: 0.9902257323265076, Score: 0.2318840579710145\n",
      "Epoch 64, Train, loss: 0.8847663402557373, Score: 0.31613756613756616\n",
      "Epoch 64, Validation, loss: 0.9845567345619202, Score: 0.24999999999999997\n",
      "Epoch 65, Train, loss: 0.8836959004402161, Score: 0.2849783397728603\n",
      "Epoch 65, Validation, loss: 0.9799558520317078, Score: 0.24999999999999997\n",
      "Epoch 66, Train, loss: 0.8816782832145691, Score: 0.26666666666666666\n",
      "Epoch 66, Validation, loss: 0.9725447297096252, Score: 0.24999999999999997\n",
      "Early stopped\n"
     ]
    }
   ],
   "source": [
    "criterion = 0\n",
    "\n",
    "for epoch_index in range(EPOCHS):\n",
    "    trainer.train_epoch(train_dataloader, epoch_index=epoch_index)\n",
    "    trainer.validate_epoch(validation_dataloader, epoch_index=epoch_index)\n",
    "     \n",
    "    # early_stopping check\n",
    "    early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "    if early_stopper.stop:\n",
    "        print('Early stopped')\n",
    "        break\n",
    "\n",
    "    if trainer.validation_score > criterion:\n",
    "        # 모델이 개선됨 -> 검증 점수와 weight 갱신\n",
    "        criterion = trainer.validation_score\n",
    "        check_point = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "        }\n",
    "        torch.save(check_point, os.path.join(ROOT_PATH, 'best.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea40a4-530f-4a4e-aeec-6e5fd14dcaf2",
   "metadata": {},
   "source": [
    "## 추론\n",
    "테스트 데이터의 타겟 변수를 `submit` 양식에 맞춰 저장한 파일을 aiconnect 플랫폼을 통해 제출하면 추론 점수를 확인할 수 있습니다.  \n",
    "\n",
    "`answer` 컬럼 값을 여러분의 모델의 추론 결과로 채워 제출 파일을 만듭니다 (현재는 모두 동일한 값으로 채워져 있습니다).\n",
    "\n",
    "ID값을 기준으로 채점을 진행하는 점 유의해주시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5b291da-1111-4ff3-867e-fa7e533b9784",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = 'test'\n",
    "                \n",
    "        # 인코딩을 위한 레이블 딕셔너리\n",
    "        self.states = {'CN': 0, 'MCI': 1, 'Dem': 2}\n",
    "        self.inputs = self.data_loader(data_dir)\n",
    "\n",
    "    def data_loader(self, path):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "            \n",
    "        if os.path.isfile(os.path.join(self.data_dir, self.mode, self.mode + '_X.pt')):\n",
    "            inputs = torch.load(os.path.join(self.data_dir, self.mode, self.mode + '_X.pt'))\n",
    "\n",
    "        else:\n",
    "            inputs = pd.read_csv(os.path.join(self.data_dir, self.mode, self.mode + '.csv'))\n",
    "            inputs = self.preprocessing(inputs)\n",
    "            torch.save(inputs, os.path.join(self.data_dir, self.mode, self.mode + '_X.pt'))\n",
    "            \n",
    "        return inputs\n",
    "        \n",
    "    \n",
    "    def preprocessing(self, inputs):\n",
    "        print('Preprocessing ' + self.mode + ' dataset..')\n",
    "        \n",
    "        # Cut time series length based on the shortest length\n",
    "        train_df = pd.read_csv(os.path.join(DATA_DIR,'train','train.csv'))\n",
    "        test_df = pd.read_csv(os.path.join(DATA_DIR,'test','test.csv')) \n",
    "        time_series_length= pd.concat([train_df['EMAIL'].value_counts(), test_df['EMAIL'].value_counts()])\n",
    "        shortest_length = time_series_length[-1]\n",
    "\n",
    "        for id in inputs['EMAIL'].unique():\n",
    "            idx = inputs['EMAIL'][inputs['EMAIL'] == id].index\n",
    "            start_idx = idx[0]\n",
    "            end_idx = idx[-1]\n",
    "            inputs.drop(list((range(start_idx + shortest_length , end_idx+1))), axis=0, inplace=True)\n",
    "            inputs = inputs.reset_index(drop=True)\n",
    "\n",
    "        # Selecting usage columns\n",
    "        del_col = ['EMAIL', 'summary_date',\n",
    "                   'activity_class_5min', 'activity_met_1min',\n",
    "                   'sleep_hr_5min', 'sleep_hypnogram_5min', 'sleep_rmssd_5min', 'timezone', 'sleep_total',\n",
    "                   'CONVERT(activity_class_5min USING utf8)', 'CONVERT(activity_met_1min USING utf8)',\n",
    "                   'CONVERT(sleep_hr_5min USING utf8)', 'CONVERT(sleep_hypnogram_5min USING utf8)',\n",
    "                   'CONVERT(sleep_rmssd_5min USING utf8)']\n",
    "        inputs.drop(del_col, axis=1, inplace=True)\n",
    "\n",
    "        #Normalization\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        if self.mode == 'test' :\n",
    "            train_df.drop(del_col, axis=1, inplace=True)\n",
    "            scaler.fit_transform(train_df)\n",
    "            inputs = scaler.transform(inputs)\n",
    "        else:\n",
    "            inputs = scaler.fit_transform(inputs)\n",
    "\n",
    "        # Convert dataframe to tensor\n",
    "        inputs = torch.FloatTensor(inputs).reshape(len(test_df['EMAIL'].unique()), -1, inputs.shape[1])\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75d03484-4059-4055-a542-530ba9d23be8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset..\n"
     ]
    }
   ],
   "source": [
    "TRAINED_MODEL_PATH = os.path.join(ROOT_PATH, 'best.pt')\n",
    "\n",
    "# Load dataset & dataloader\n",
    "test_dataset = TestDataset(data_dir=DATA_DIR)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Load Model\n",
    "model = LSTM(input_dim=test_dataset.inputs.shape[2], hidden_dim=512, output_dim=3, device=device).to(device)\n",
    "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])\n",
    "model.eval()\n",
    "\n",
    "# Set metrics & Loss function\n",
    "pred_lst = []\n",
    "with torch.no_grad():\n",
    "    for batch_index, data in enumerate(test_dataloader):\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        pred_lst.extend(output.argmax(dim=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97177643-778d-414e-b9d0-28b9cf2047a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44a7952c-2750-4c75-96f9-c2cc768f0204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CN', 'CN', 'CN', 'CN', 'CN']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추론 결과 디코드\n",
    "for i in range(len(pred_lst)):\n",
    "    if pred_lst[i] == 0:\n",
    "        pred_lst[i] = 'CN'\n",
    "    elif pred_lst[i] == 1:\n",
    "        pred_lst[i] = 'MCI'\n",
    "    else:\n",
    "        pred_lst[i] = 'Dem'\n",
    "pred_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44fab4b4-148a-48c6-8bb8-1b51e32768e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DIAG_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nia+075@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nia+480@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nia+157@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nia+601@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nia+194@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID DIAG_NM\n",
       "0  nia+075@rowan.kr      CN\n",
       "1  nia+480@rowan.kr      CN\n",
       "2  nia+157@rowan.kr      CN\n",
       "3  nia+601@rowan.kr      CN\n",
       "4  nia+194@rowan.kr      CN"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv(\"sample_submission.csv\") \n",
    "submit = pd.DataFrame(submit)\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b689691-5c29-4ef7-9a2d-dd55c5e21efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DIAG_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nia+075@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nia+480@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nia+157@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nia+601@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nia+194@rowan.kr</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID DIAG_NM\n",
       "0  nia+075@rowan.kr      CN\n",
       "1  nia+480@rowan.kr      CN\n",
       "2  nia+157@rowan.kr      CN\n",
       "3  nia+601@rowan.kr      CN\n",
       "4  nia+194@rowan.kr      CN"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['DIAG_NM'] = pred_lst\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3725b2ef-14c1-48df-b6e8-f3f914f24a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 제작\n",
    "submit.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff91aae-1327-4a42-9868-e4b548a2d210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf34025-16d1-4b44-9a23-f2690af92eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38437635-8464-4750-a65e-9ce12ad4f077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score=0.28144078144078144,pScore=0.2222222222222222\n",
      "Elapsed Time: 0.11734509468078613\n"
     ]
    }
   ],
   "source": [
    "!python evaluate.py answer.csv submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc682d9-43ab-49db-9f15-c3412236543f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
